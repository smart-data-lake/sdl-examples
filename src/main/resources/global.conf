#
# Smart Data Lake - Build your data lake the smart way.
#
# Copyright Â© 2019 ELCA Informatique SA (<https://www.elca.ch>)
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.
#

global {
  sparkOptions {
    "hive.exec.dynamic.partition" = true
    "hive.exec.dynamic.partition.mode" = nonstrict
    "spark.sql.sources.partitionOverwriteMode" = dynamic
    "spark.shuffle.service.enabled" = true
    "spark.rdd.compress" = true
    "spark.checkpoint.compress" = true

    // sizing, should normally be set by spark-submit parameters
    //"spark.executor.cores": "4",
    //"spark.executor.memory": "8G",
    //"spark.yarn.executor.memoryOverhead": "2048"

    // dynamic allocation
    //"spark.dynamicAllocation.enabled" = true
    //"spark.dynamicAllocation.minExecutors" = 0
    //"spark.dynamicAllocation.maxExecutors" = 15,
    //"spark.dynamicAllocation.executorIdleTimeout" = 300s,
    //"spark.dynamicAllocation.cachedExecutorIdleTimeout" = 1h,

    // others
    //"spark.sql.parquet.writeLegacyFormat" = true // to write parquet in legacy format for hive compatibility
    //"spark.default.parallelism" = 200 // should normally be set per action with property parallelism (to be implemented)
    //"spark.files.maxPartitionBytes" = 134217728 // default is 128Mb, that's a good value
  }
}